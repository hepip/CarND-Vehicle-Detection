{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from helper import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicle files: 8792\n",
      "Number of non-vehicle files: 8968\n"
     ]
    }
   ],
   "source": [
    "##Load the data\n",
    "vehicle_files_dir = './data/vehicles/'\n",
    "non_vehicle_files_dir = './data/non-vehicles/'\n",
    "vehicle_files = extract_files(vehicle_files_dir)\n",
    "non_vehicle_files = extract_files(non_vehicle_files_dir)\n",
    "\n",
    "print('Number of vehicle files: {}'.format(len(vehicle_files)))\n",
    "print('Number of non-vehicle files: {}'.format(len(non_vehicle_files)))\n",
    "\n",
    "#Push images location to cars and not cars data structure\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "for car in vehicle_files:\n",
    "    cars.append(car)\n",
    "for objs in non_vehicle_files:\n",
    "    notcars.append(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Training Parameters\n",
    "\n",
    "### Tweak these parameters and see how the results change.\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = False # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [490, 700] # Min and max in y to search in slide_window()\n",
    "\n",
    "classifer_pickle = 'svc_car_classifier.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction Started\n",
      "Feature Extraction Ended\n",
      "93.86 Seconds to extract features...\n"
     ]
    }
   ],
   "source": [
    "# Extract the color and hog features\n",
    "t = time.time()\n",
    "print('Feature Extraction Started')\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print('Feature Extraction Ended')\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Preprocessing Started\n",
      "Feature Preprocessing Ended\n",
      "4.52 Seconds to extract features...\n"
     ]
    }
   ],
   "source": [
    "## Stack and Preprocess\n",
    "t = time.time()\n",
    "print('Feature Preprocessing Started')\n",
    "\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "print('Feature Preprocessing Ended')\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 8364\n",
      "Starting to train at  1489281233.304897\n",
      "Starting to do Grid Search for parameters..\n",
      "Training the classifier..\n",
      "4534.78 Seconds to train the classfier...\n",
      "Test Accuracy of SVC =  0.9969\n",
      "Model saved to Pickle file\n"
     ]
    }
   ],
   "source": [
    "#The Classifier Trainer\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "# Check the training time for the SVC\n",
    "\n",
    "t=time.time()\n",
    "print('Starting to train at ', t)\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0, 10]}\n",
    "svr = svm.SVC(verbose=1)\n",
    "\n",
    "print('Starting to do Grid Search for parameters..')\n",
    "svc = GridSearchCV(svr, parameters)\n",
    "print('Training the classifier..')\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train the classfier...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "_ = joblib.dump(svc, classifer_pickle, compress=9)\n",
    "print('Model saved to Pickle file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Finaly after 1.25 Hours got my pickle created"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
